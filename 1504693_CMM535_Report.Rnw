\documentclass[10pt  ,usenames, dvipsnames]{article}
\usepackage{graphicx, verbatim}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{lipsum}
\usepackage{todonotes}
\usepackage[tableposition=top]{caption}
\usepackage{ifthen}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{listings}
\usepackage{color}
\setlength{\textwidth}{6.5in} 
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in} 
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-1.5cm}
\setlength{\parindent}{0cm}
\usepackage{setspace}
\usepackage{float}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{tabularx}
\usepackage{lmodern} % for bold teletype font
\usepackage{minted}
\usepackage{underscore}

\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = red %Colour of citations
}

%\fancyhf{}
\rfoot{Andrew Tait \thepage}
\singlespacing
\usepackage[affil-it]{authblk} 
\usepackage{etoolbox}
\usepackage{lmodern}

% Notice the following package, it will help you cite papers
\usepackage[backend=bibtex ,sorting=none]{biblatex}
\bibliography{references}




\begin{document}


\title{\LARGE Coursework  \\ Data Science Development (CMM535)}

\author{Andrew Tait, \textit{\href{1504693@rgu.ac.uk}{1504693@rgu.ac.uk}}}
\maketitle
% \begin{flushleft} \today \end{flushleft} 
\noindent\rule{16cm}{0.4pt}
%\underline{\hspace{3cm}
\ \\
%\thispagestyle{empty}



\section {Data Exploration}



\subsection{Dataset Choice}
The dataset that has been chosen for this part of the coursework is Mushroom. This is available on the UCI repository. The set was chosen because of it's adequate instance size and number of attributes.

\url{http://archive.ics.uci.edu/ml/datasets/Mushroom}



\subsection{Problem Statement and Data Exploration}


The main purpose of the Mushroom dataset is to identify which characteristics (attributes) determine if a particular mushroom species is editable or poisonous.

Therefore the aim of this assignment is to build a predictive model to predict if a certain type of Mushroom is edible or not.


To start off the data exploration I will first import the required packages.

<<warning=FALSE,eval=FALSE,comment=FALSE>>=
#Import packages
library(randomForest)  
library(e1071)  
library(caret)  
library(ggplot2) 
library(gridExtra)
library(caret)
library(rpart.plot)
library(RColorBrewer)
library(plyr)
library(dplyr)
library(doParallel)
library(xtable)
@

<<warning=FALSE,echo=FALSE, comment=FALSE, message=FALSE>>==
#Import packages
library(randomForest)  
library(e1071)  
library(caret)  
library(ggplot2) 
library(gridExtra)
library(caret)
library(rpart.plot)
library(RColorBrewer)
library(plyr)
library(dplyr)
library(doParallel)
library(xtable)
@


Then set the working directory to the Coursework project folder path:
<<eval=FALSE,comment=TRUE>>=
setwd("~/CMM535 Data Science Development/Coursework/CMM535_Coursework")
@

<<warning=FALSE,echo=FALSE, comment=FALSE, message=FALSE>>==
setwd("~/CMM535 Data Science Development/Coursework/CMM535_Coursework")
@

In order to import the dataset, I used a third party helper function, which can be viewed at (Figure~\ref{figHelper})  .
The helper function not only set the attributes names but the instances names as well. Since all the data is represented a single character, it converts them into their string equivalent.


<<eval=FALSE,comment=TRUE>>=
#helper function
source('helper_functions.r')

#Import datasets using helper function

mushroom <- fetchAndCleanData()
@


<<warning=FALSE,echo=FALSE>>==
#helper function
source('helper_functions.r')

#Import datasets using helper function

mushroom <- fetchAndCleanData()
@


Now that the dataset is imported, it is time to do some data exploration and analysis.

Number of rows in the dataset:

<<eval=FALSE,comment=TRUE>>=
#Number of rows in the dataset
nrow(mushroom)

@


<<warning=FALSE,echo=FALSE>>==

#Number of columns in the dataset
nrow(mushroom)

@

Number of columns (features) in the dataset:

<<eval=FALSE,comment=TRUE>>==
ncol(mushroom)

@


<<warning=FALSE,echo=FALSE>>==
ncol(mushroom)

@

Summary of the Mushroom dataset:

<<eval=FALSE,comment=TRUE>>==
#Summary of the Mushroom dataset
str(mushroom)

@


<<warning=FALSE,echo=FALSE>>==
str(mushroom)

@

Now that some basic data exploration is covered, next to inspect the dataset a bit further. Starting with the class (Edible) distribution in the mushroom dataset, see (Figure~\ref{fig1})

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Class Distribution
barplot(table(mushroom$Edible))
@

\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,fig.height=4.5,out.width=".76\\linewidth">>=
barplot(table(mushroom$Edible))
@
\caption {Barplot of Class Distribution}
\label{fig1}
\end {center}
\end {figure}

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Class Distribution
summary(mushroom$Edible)
@


<<warning=FALSE,echo=FALSE>>==
summary(mushroom$Edible)
@

As shown in the above summary and graphs, the dataset is not unbalanced with the Edible class that has 4208 instances(51.7971 percent) and the Poisonous class that has 3916 instances (48.20 percent) in the dataset.
\clearpage

Next is to analyse if there is a cor-relocation between the CapShape and CapSurface of a mushroom and whether it is Edible or Poisonous. Which is shown in the plot (Figure~\ref{fig2}) below.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==

#Comparisons of CapShape and CapSurface with Edible or Poisonous
ggplot(mushroom,aes(x=CapShape, y=CapSurface, color=Edible)) + 
                       geom_jitter(alpha=0.3) +
                       scale_color_manual(breaks = c('Edible','Poisonous'), 
                                          values=c('darkgreen','red'))
                                                                                
@




\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,fig.height=4.5,out.width=".76\\linewidth">>=

ggplot(mushroom,aes(x=CapShape, y=CapSurface, color=Edible)) + 
                       geom_jitter(alpha=0.3) +
                       scale_color_manual(breaks = c('Edible','Poisonous'), 
                                          values=c('darkgreen','red'))
                                                                                
@
\caption {Comparisons of CapShape and CapSurface with Edible or Poisonous in Mushroom Dataset}
\label{fig2}
\end {center}
\end {figure}

As the plot above shows, there is a correlation between the Capshape and Capsurface of a Mushroom and whether it's Edible or not. For instance if the Capshape is either Convex or flat there is high chance it will be Poisonous. On the side if the Capshape is Surken and the CapSurface Fibrous then it will be a Edible Mushroom.

\clearpage

The last data exploration task to do is to analyse if there is a cor-relocation between the StalkSurfaceAboveRing and StalkSurfaceBelowRing of a mushroom and whether it is Edible or Poisonous. Which is shown in the plot (Figure~\ref{fig3}) below.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==

#Comparisons of StalkSurfaceAboveRing and StalkSurfaceBelowRing with Edible or Poisionous
ggplot(mushroom,aes(x=StalkSurfaceAboveRing, y=StalkSurfaceBelowRing, color=Edible)) + 
  geom_jitter(alpha=0.3) +
  scale_color_manual(breaks = c('Edible','Poisonous'), values=c('darkgreen','red'))          

@

\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,fig.height=4.5,out.width=".76\\linewidth">>=

#Comparisons of StalkSurfaceAboveRing and StalkSurfaceBelowRing with Edible or Poisionous
ggplot(mushroom,aes(x=StalkSurfaceAboveRing, y=StalkSurfaceBelowRing, color=Edible)) + 
  geom_jitter(alpha=0.3) +
  scale_color_manual(breaks = c('Edible','Poisonous'), values=c('darkgreen','red'))
                                                                                
@
\caption {Comparisons of StalkSurfaceAboveRing and StalkSurfaceBelowRing with Edible or Poisionous}
\label{fig3}
\end {center}
\end {figure}

There is a bit more of a mix between the classes in this graph. The main cluster that sticks it out is if both the StalkSurfaceBelowRing and StalkSurfaceAboveRing is Silky then the mushroom is going to be Poisionous, the vast majority of the time. On the other hand if the 
StalkSurfaceAboveRing is Smooth and the StalkSurfaceBelowRing is Scaly then the mushroom will be Edible.

\clearpage

\subsection {Pre-Processing}

Before the Mushroom dataset can be processed by a classification model(s), some pre-processing is required.

While the helper function should take out all missing values, lets validate this before continuing.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Class Distribution
table(complete.cases (mushroom))
@


<<warning=FALSE,echo=FALSE>>=
#Class Distribution
table(complete.cases (mushroom))
@

As shown above, there is not any missing values in the dataset.


\clearpage



\section {Modeling and Classification}



\subsection {Divide into training and testing subset}

When it came to dividing the mushroom dataset into training and testing subsets, I decided to go with  60 percent
training and 40 percent testing split as a starting point/baseline. This is to prevent over fitting from occurring.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Divide the dataset into 60% training and 40% testing, to prevent overfitting from occurring
inTrain <- createDataPartition(y=mushroom$Edible, p=0.6, list=FALSE)

#Assign indexes to split the Mushroom dataset into training and testing
training <- mushroom[inTrain,]
testing <- mushroom[-inTrain,]
@

<<warning=FALSE,echo=FALSE>>=
#Divide the dataset into 60% training and 40% testing.
inTrain <- createDataPartition(y=mushroom$Edible, p=0.6, list=FALSE)

#Assign indexes to split the Mushroom dataset into training and testing
training <- mushroom[inTrain,]
testing <- mushroom[-inTrain,]
@



\subsection{Build Classifier}

For the initial classifier I decided to go with the kNN Classifier as it has proven to be a good baseline in previous labs and exercises in R.


Before the classification begins, parallel processing is enabled to speed up this process.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Setup Parallel processing to speed up classification modelling 
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
@

<<warning=FALSE,echo=FALSE>>=
#Setup Parallel processing to speed up classification modelling 
cl <- makeCluster(detectCores(), type='PSOCK')
registerDoParallel(cl)
@

The train control is set to cross-validation with 10 folds:
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#set train control to cross-validation with 10 folds
train_control<- trainControl(method="cv", number=10,verboseIter=FALSE)
@

<<warning=FALSE,echo=FALSE>>=
#set train control to cross-validation with 10 folds
train_control<- trainControl(method="cv", number=10,verboseIter=FALSE)
@


Next the seed is set to 1, in order to make the module reproducible and the kNN model is set up with the train_control from above and the tune length of 10.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#First set the seed for reproducibility
set.seed(1)

#train model using kNN
kNNModel <- train(Edible ~ ., data = training, 
                  trControl = train_control, 
                  tuneLength =10,
                  method = "knn",
                  metric = 'Accuracy'
)
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>=
#First set the seed for reproducibility
set.seed(1)

#train model using kNN
kNNModel <- train(Edible ~ ., data = training, 
                  trControl = train_control, 
                  tuneLength =10,
                  method = "knn",
                  metric = 'Accuracy'
)
@

\clearpage
Once the knn Model is complete, it's time to analyse the results, first with a print of the kNNModel as shown below.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Show the kNN model results
kNNModel
@



<<warning=FALSE,echo=FALSE,cache=TRUE>>=
#Show the kNN model results
kNNModel

@

As the print out of the kNNModel shows, the accuracy is very high (99.38 percent) and the k value selected for the model is 5.


\clearpage

Next is a confusion matrix is created by predicting the accuracy against the testing (40 percent of the total dataset) subset.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==

#Predict the accuracy of the kNN Model against the testing set
predictkNN <- predict(kNNModel,testing)
confusionMatrix(predictkNN, testing$Edible)
@



<<warning=FALSE,echo=FALSE,cache=TRUE>>=

#Predict the accuracy of the kNN Model against the testing set
predictkNN <- predict(kNNModel,testing)
confusionMatrix(predictkNN, testing$Edible)
@

When the kNNModel is predicted against the testing subset, it returns with 100 Percent Accuracy. As 1683 of the instances were correctly classified as 'Edible' and 1566 of instances were correctly classed as 'Poisonous'. The kappa value was also value of one. 




\clearpage


\subsection{Improve Model Performance}

As discussed in the previous section, the kNNModel produced 100 percent Accuracy so there isn't much too improve on that particular model. Therefore I've decided to test the Mushroom dataset against two different classifiers: c5.0 and Random forest. The train control setting remains the same from kNN, for a fair comparison.

\subsubsection{C5.0 Model}

First off the seed is set for reproducibility and the tune length is to 5 (takes less time and still produces accurate results).
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#First set the seed for reproducibility
set.seed(1)

#train the model using c5.0
c50Model<- train(Edible~., data=training,
                 trControl=train_control,
                 tuneLength=5, 
                 method="C5.0"
)
@


<<warning=FALSE,echo=FALSE, cache=TRUE>>=
set.seed(1)
c50Model<- train(Edible~., data=training,
                 trControl=train_control,
                 tuneLength = 10,
                 method="C5.0"
)
@

Once the C5.0 model is completed, it's results are outlined below.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Show the c50Model results
 c50Model
@




<<warning=FALSE,echo=FALSE, cache=TRUE>>=
#Show the c50Model results
c50Model
@

As shown in the results above the accuracy of the c5.0 model is 100 percent like the kNN Model but on the first trail run.

\clearpage

Next is a confusion matrix is created by predicting the accuracy against the testing (40 percent of the total dataset) subset.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Predict the accuracy of the c5.0 Model against the testing set
predictC50 <- predict(c50Model, testing)
confusionMatrix(predictC50,testing$Edible)
@



<<warning=FALSE,echo=FALSE,cache=TRUE>>=
predictC50 <- predict(c50Model, testing)
confusionMatrix(predictC50,testing$Edible)
@

When the C5.0 Model is predicted against the testing subset, it returns with 100 Percent Accuracy. As 1683 of the instances were correctly classified as 'Edible' and 1566 of instances were correctly classed as 'Poisonous'. The kappa value was also value of one. 


\clearpage

\subsubsection{Random forest Model}

First off the seed is set for reproducibility and the tune length is to 10.
As in the previous models the train control remains the same.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#First set the seed for reproducibility
set.seed(1)

# train the model using random forest
RFModel<- train(Edible~., data=training,
                trControl=train_control,
                method="rf",
                tuneLength =10,
                metric = 'Accuracy'
)

@


<<warning=FALSE,echo=FALSE, cache=TRUE>>=

#First set the seed for reproducibility
set.seed(1)

# train the model using random forest
RFModel<- train(Edible~., data=training,
                trControl=train_control,
                method="rf",
                tuneLength =10,
                metric = 'Accuracy'
)
@

Once the Random forest model is completed, its results are outlined below.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Show the results from the random forest model
RFModel
@


<<warning=FALSE,echo=FALSE,cache=TRUE>>=
RFModel
@

As shown in the results above the accuracy of the c5.0 model is 100 percent like the kNN Model and c5.0 model but the mtry value is to 22. 

\clearpage
Next is a confusion matrix is created by predicting the accuracy against the testing (40 percent of the total
dataset) subset.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Predict the accuracy of the rf Model against the testing set
predictRF <- predict(RFModel,testing)
confusionMatrix(predictRF, testing$Edible)
@


<<warning=FALSE,echo=FALSE,cache=TRUE>>=
predictRF <- predict(RFModel,testing)
confusionMatrix(predictRF, testing$Edible)
@

When the Random forest model is predicted against the testing subset, it returns with 100 Percent Accuracy. As 1683 of the instances were correctly classified as 'Edible' and 1566 of instances were correctly classed as 'Poisonous'. The kappa value was also value of one. 

\clearpage

In addition to the confusion matrix, a Variable importance plot is produced from the Random forest model. As shown in (Figure~\ref{fig4})

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Show which variables are most important from the RF Model
varImpPlot(RFModel$finalModel,main = 'Variable Importance')
@

\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,fig.height=6.5,out.width="1\\linewidth">>=
varImpPlot(RFModel$finalModel,main = 'Variable Importance')
@
\caption {Variable Importance based on the RFModel Results}
\label{fig4}
\end {center}
\end {figure}

The most important variable based on the plot above, is OderNone with MeanDecreaseGini value of 350+. Followed by the OderFoul variable  with around MeanDecreaseGini value of 250.

This means that the smell of a Mushroom is the strongest indicator of whether it is classified  as Edible or Poisonous.

\clearpage


\subsubsection{Comparison of all Models}

Finally the three classification models are compared against each other.
To do this they are re sampled as a list and then plotted using a bwplot.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
rs <- resamples(list(kNN = kNNModel, 
                     c50 = c50Model, 
                     rf = RFModel))
summary(rs)
bwplot(rs)
@
<<warning=FALSE,echo=FALSE>>==
rs <- resamples(list(kNN = kNNModel, 
                     c50 = c50Model, 
                     rf = RFModel))
summary(rs)
@

The summary of all three models is that the c50 and random forest models are identical in accuracy and kappa values. While the kNN model is slightly lower at 99.794 percent for it's minimal accuracy value.


\begin{figure}[H]
\begin{center}
<<warning=FALSE,echo=FALSE,fig.height=6.5,out.width="0.75\\linewidth">>=

bwplot(rs)
@
\caption {Comparison of kNN, C5.0 and Random Forest Models}
\label{fig5}
\end {center}
\end {figure}


The box plot illustrates that the performance between all three models is very similar. 
While the C5.0 and random forest models, performed the same in terms of accuracy and kappa values, I decided to go with the Random forest model to use in the Clustering exercise.



\clearpage



\section{Fine-grained Model}


\subsection{Clustering Dataset}

\subsubsection{Pre-processing}

Before the dataset can be turned into clusters, there is some pre-processing required.
First a normalize data function is setup.


<<warning=FALSE,eval=FALSE,comment=TRUE>>==
normalizeData <- function (x ) {
return ( (x-min(x) ) / ( max(x)- min(x) ))
}
@



<<warning=FALSE,echo=FALSE, cache=TRUE>>=
normalizeData <- function (x ) {
return ( (x-min(x) ) / ( max(x)- min(x) ))
}
@


% Clustering function to run (displayed as a listing at the end of the doc)

<<warning=FALSE,echo=FALSE, cache=TRUE>>=
#Clustering Function
clustData <- function (df,ClassIndex,kmeansClasses = rep(0,unique(df[,ClassIndex]))) {
  # use split function to split the dataset according to the class label
  # a set of dataframes each representing a class label will be stored
  # in dfs list()
  dfs <- split (df, df[,ClassIndex])
  # create empty list
  clustList <- list()
  n <- length(dfs)
  for (i in 1:length(kmeansClasses)){
    # Cluster according to all features excluding the label
    if (kmeansClasses[i]>1 & kmeansClasses[i]< nrow(dfs[[i]])){
      clustList[[i]] <- kmeans(dfs[[i]][,-ClassIndex],kmeansClasses[i])
      #plotcluster(clustList[[i]], clustList[[i]]$cluster)
      dfs[[i]]$cluster <- paste0((dfs[[i]][,ClassIndex]),
                                 "_","c",clustList[[i]]$cluster)
    }
    else {
      dfs[[i]]$cluster = paste0((dfs[[i]][,ClassIndex]),
                                "_c0")
    }
  }
  # put all list elements in a dataframe and return it
  # note that ldply() require the library plyr
  allClusteredElements <- ldply (dfs, data.frame)
  # drop the first column 'id' resulting from ldply
  allClusteredElements <- allClusteredElements[,-1]
  allClusteredElements <- allClusteredElements[,-ClassIndex]
  return(allClusteredElements)
}
@

Next the mushroom (clean) dataset is copied to a data frame variable dfNew. The vieltype attribute is also removed, as this caused errors that prevented the clustering function from running.

The instances are turned into numerical values and then normalized.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Copy the dataset before pre-processing 
dfNew <- mushroom
dfNew$VeilType <- NULL

#Convert the dataframe to numeric values
dfNew[,2:22] = lapply(dfNew[,2:22], as.numeric)

##Then use the normalise function from above
dfN <- as.data.frame(lapply(dfNew[,-1], normalizeData))
@

<<warning=FALSE,echo=FALSE>>=


#Copy the dataset before pre-processing 
dfNew <- mushroom
dfNew$VeilType <- NULL

#Convert the dataframe to numeric values
dfNew[,2:22] = lapply(dfNew[,2:22], as.numeric)

##Then use the normalise function from above
dfN <- as.data.frame(lapply(dfNew[,-1], normalizeData))

@



\subsubsection{Clustering using clustData function}


The edible class is then added back to the data frame dfN after normlization process is complete.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
str(dfN)
dfN$Edible <- dfNew$Edible

table(complete.cases (dfN))


@
The dataframe is now numerical and contains no missing values.

<<warning=FALSE,echo=FALSE>>=
str(dfN)
dfN$Edible <- dfNew$Edible

table(complete.cases (dfN))


@

The provided clustering function see Figure~\ref{figCluster}), is then run with the clustering options set to 2 as there is only 2 classes.
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
clusteredDF <- clustData(dfN,ncol(dfNew), c(2,2))
head(clusteredDF,10)
@

<<warning=FALSE,echo=FALSE>>=
clusteredDF <- clustData(dfN,ncol(dfNew), c(2,2))
head(clusteredDF,10)
@

\clearpage
\subsection{Adapting your Model}


\subsubsection{Refitting Random Forest to Clustering}

The clusteredDF is now going to be run through the same Random forest model as in section 2.3.2. 
With the the 60 percent training and 40 percent training split. 

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Adapting the model

#Divide the datset into 60% training and 40% testing.
inTrainCluster <- createDataPartition(y=clusteredDF$cluster, p=0.6, list=FALSE)



#Assign indexes to split the Mushroom dataset into training and testing
trainingCluster <- clusteredDF[inTrainCluster,]
testingCluster <- clusteredDF[-inTrainCluster,]

#set train control to cross-validation with 5 folds
train_controlCluster<- trainControl(method="cv", number=10,verboseIter=FALSE)

@



<<warning=FALSE,echo=FALSE,cache=TRUE>>=
#Adapting the model

#Divide the datset into 60% training and 40% testing.
inTrainCluster <- createDataPartition(y=clusteredDF$cluster, p=0.6, list=FALSE)


#Assign indexes to split the Mushroom dataset into training and testing
trainingCluster <- clusteredDF[inTrainCluster,]
testingCluster <- clusteredDF[-inTrainCluster,]

#set train control to cross-validation with 5 folds
train_controlCluster<- trainControl(method="cv", number=10,verboseIter=FALSE)
@
First off the seed is set for reproducibility and the tune length is set to 10.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#First set the seed for reproducibility
set.seed(1)

# train the model using random forest
RFModelCluster<- train(cluster~., data=trainingCluster,
                trControl=train_controlCluster,
                method="rf",
                tuneLength =10,
                metric = 'Accuracy'
)
#Show Random forest model
RFModelCluster
@

\clearpage
Once the Random forest clustering model is completed, its results are outlined below.
<<warning=FALSE,echo=FALSE,cache=TRUE>>=
#First set the seed for reproducibility
set.seed(1)

# train the model using random forest
RFModelCluster<- train(cluster~., data=trainingCluster,
                trControl=train_controlCluster,
                method="rf",
                tuneLength =10,
                metric = 'Accuracy'
)
#Show Random forest model
RFModelCluster
@
The accuracy of Random forest model has decreased slightly when using the clustered dataset with the highest value of 0.9995902 percent accuracy and 0.9994507 kappa.


\clearpage
Next is a confusion matrix is created by predicting the accuracy against the testing (40 percent of the total
dataset) subset
<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Predict the accuracy and display using a confusion matrix
predictRFCluster <- predict(RFModelCluster,testingCluster)
confusionMatrix(predictRFCluster, testingCluster$cluster)
@

<<warning=FALSE,echo=FALSE,cache=TRUE>>=
#Predict the accuracy and display using a confusion matrix
predictRFCluster <- predict(RFModelCluster,testingCluster)
confusionMatrix(predictRFCluster, testingCluster$cluster)
@

The confusion matrix shows an overall accuracy of  0.9997 percent and there is one incorrectly classified cluster: Edible_c1 classified as Edible_c2.

\clearpage
\subsubsection{Results}

To display the results, the actual and predicted results are split into two variables.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Split the actual results
actual <- testingCluster$cluster
str(actual)

#Split the predicted Results
pred <- predictRFCluster
str(pred)
@


<<warning=FALSE,echo=FALSE,cache=TRUE>>=
#Split the actual results
actual <- testingCluster$cluster
str(actual)

#Split the predicted Results
pred <- predictRFCluster
str(pred)
@

The actual and predicted values are then combined to a single dataframe.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Combine the actual and predicted results into a dataframe.
cols = data.frame("Actual" = actual, "Predicted" = pred)

#Convert the both the actual and predict results to characters
cols$Actual <- as.character(cols$Actual)
cols$Predicted <- as.character(cols$Predicted)
@

The instance values of each of the results are then converted to characters.
<<warning=FALSE,echo=FALSE,cache=TRUE>>=
#Combine the actual and predicted results into a dataframe.
cols = data.frame("Actual" = actual, "Predicted" = pred)

#Convert the both the actual and predict results to characters
cols$Actual <- as.character(cols$Actual)
cols$Predicted <- as.character(cols$Predicted)
@

The results placeholder has be initialize prior to the for loop been run.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#initlise results variable outside for-loop to null
results <- NULL
@


<<warning=FALSE,echo=FALSE>>=
#initlise results variable outside for-loop to null
results <- NULL
@


The for loop below, for the total number of rows in the cols dataframe. It then splits the actual and predicted results for that row into variables.

The supplied substr code then compares the two values and removes the last three characters.
If the two results are the same then it will store 'Yes' in the results dataframe else 'No'.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Loop for all the rows in cols dataframe
for(row in 1:nrow(cols)){
  
  #split actual/pred again within for loop
  actualRow <- cols$Actual[row]
  predRow <- cols$Predicted[row]
  
  #Remove the last three characters in the actual/predicted results 
  # then check if they are the same
  results[row] <- substr(actualRow, 0,nchar(actualRow)-3)== substr(predRow,0, nchar(predRow)-3)
  
  #If results are the same(TRUE) then set 'Yes' otherwise then 'No'
  if(results[row] == TRUE){
    results[row] <- 'Yes'
  } else{
    results[row] <- 'No'
  }
}
@




<<warning=FALSE,echo=FALSE>>=
#Loop for all the rows in cols dataframe
for(row in 1:nrow(cols)){
  
  #split actual/pred again within for loop
  actualRow <- cols$Actual[row]
  predRow <- cols$Predicted[row]
  
  #Remove the last three characters in the actual/predicted results 
  # then check if they are the same
  results[row] <- substr(actualRow, 0,nchar(actualRow)-3)== substr(predRow,0, nchar(predRow)-3)
  
  #If results are the same(TRUE) then set 'Yes' otherwise then 'No'
  if(results[row] == TRUE){
    results[row] <- 'Yes'
  } else{
    results[row] <- 'No'
  }
}
@



\clearpage

Once the for-loop is complete, all the results are binded into one dataframe. The results this dataframe are shown in the following three tables.

<<warning=FALSE,eval=FALSE,comment=TRUE>>==
#Bind the actual, predicted and correct results together.
finalResults = cbind(cols, "Correct" =results)
@


<<warning=FALSE,echo=FALSE>>=
#Bind the actual, predicted and correct results together.
finalResults = cbind(cols, "Correct" =results)
@



% latex table generated in R 3.4.2 by xtable 1.8-2 package
% Sun Apr 22 15:14:57 2018
\begin{table}[ht]
\centering
\caption{Confusion Matrix of RF Cluster Model - 100 percent Accuracy}
\begin{tabular}{rrrrr}
  \hline
 & Edible\_c1 & Edible\_c2 & Poisonous\_c1 & Poisonous\_c2 \\ 
  \hline
Edible\_c1 & 1145 &   0 &   0 &   0 \\ 
  Edible\_c2 &   0 & 537 &   0 &   0 \\ 
  Poisonous\_c1 &   0 &   0 & 704 &   0 \\ 
  Poisonous\_c2 &   0 &   0 &   0 & 862 \\ 
   \hline
\end{tabular}
\label{tab1}
\end{table}




% Final Results Table (Top 10)
\begin{table}[ht]
\centering
\caption{Actual, Predicted and Correct Results Table (Top 10)}
\begin{tabular}{rlll}
  \hline
 & Actual & Predicted & Correct \\ 
  \hline
1 & Edible\_c2 & Edible\_c2 & Yes \\ 
  2 & Edible\_c1 & Edible\_c1 & Yes \\ 
  3 & Edible\_c1 & Edible\_c1 & Yes \\ 
  4 & Edible\_c2 & Edible\_c2 & Yes \\ 
  5 & Edible\_c2 & Edible\_c2 & Yes \\ 
  6 & Edible\_c1 & Edible\_c1 & Yes \\ 
  7 & Edible\_c1 & Edible\_c1 & Yes \\ 
  8 & Edible\_c1 & Edible\_c1 & Yes \\ 
  9 & Edible\_c1 & Edible\_c1 & Yes \\ 
  10 & Edible\_c1 & Edible\_c1 & Yes \\ 
   \hline
\end{tabular}
\label{tab2}
\end{table}


% Final Results Table (last 10)
\begin{table}[ht]
\centering
\caption{Actual, Predicted and Correct Results Table (Bottom 10)}
\begin{tabular}{rlll}
  \hline
 & Actual & Predicted & Correct \\ 
  \hline
3239 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3240 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3241 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3242 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3243 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3244 & Poisonous\_c2 & Poisonous\_c2 & Yes \\ 
  3245 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3246 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3247 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
  3248 & Poisonous\_c1 & Poisonous\_c1 & Yes \\ 
   \hline
\end{tabular}
\label{tab3}
\end{table}

As the first table displays the clustering random forest model is 100 percent accurate. with all the clusters correctly identified.

The last two tables show the top 10 and last 10 rows of the finalresults dataframe.

Overall this Random forest model was a complete success in correctly classifying the clusters for each of the classes.



\clearpage
% The title for the reference section is called References 

\section{Appendix}

\subsection{Mushroom Dataset Helper Function}

I used a helper function to import the dataset, it helps with assigning the correct column and row names to the dataset. It also removes any missing values from the dateset.

\url{https://github.com/stoltzmaniac/Mushroom-Classification/blob/master/helper_functions.R}

\lstset{ 
  language=R,                     % the language of the code
  basicstyle=\tiny\ttfamily, % the size of the fonts that are used for the code
  stepnumber=1,                   % the step between two line-numbers. If it is 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
 keywordstyle=\color{RoyalBlue},      % keyword style
  commentstyle=\color{YellowGreen},   % comment style
  stringstyle=\color{ForestGreen}      % string literal style
} 


\label{figHelper}
\begin{figure}[H]
\caption {fetchAndCleanData Function for Mushroom dataset}
\end {figure}
    \begin{lstlisting}
fetchAndCleanData = function(){
  
  # All of this code is from
  # https://rstudio-pubs-static.s3.amazonaws.com/125760_358e4a6802c94fa29e2a9ab49f45df94.html
  
  mushrooms = read.table("data/agaricus-lepiota.data", header = FALSE, sep = ",")
  
  
  
  #create a data frame with only the required columns
  shrooms = mushrooms
  
  #column names are added
  colnames(shrooms) = c("Edible",
                        "CapShape",
                        "CapSurface",
                        "CapColor",
                        "Bruises",                        
                        "Odor",
                        "GillAttachment",
                        "GillSpacing",
                        "GillSize",
                        "GillColor",
                        "StalkShape",
                        "StalkRoot",
                        "StalkSurfaceAboveRing",
                        "StalkSurfaceBelowRing",
                        "StalkColorAboveRing",
                        "StalkColorBelowRing",
                        "VeilType",
                        "VeilColor",
                        "RingNumber",
                        "RingType",
                        "SporePrintColor",
                        "Population",
                        "Habitat")
  
  
  #Edible
  shrooms$Edible = as.character(shrooms$Edible)
  shrooms$Edible[shrooms$Edible == "e"] = "Edible"
  shrooms$Edible[shrooms$Edible == 'p'] = "Poisonous"
  shrooms$Edible = factor(shrooms$Edible)
  
  
  # Edible
  #levels(shrooms$Edible) = c(levels(shrooms$Edible), c("Poisonous","Edible"))
  #shrooms$Edible[shrooms$Edible == "p"] = "Poisonous"
  #shrooms$Edible[shrooms$Edible == "e"] = "Edible"
  
  #CapShape
  levels(shrooms$`CapShape`) = c(levels(shrooms$`CapShape`), c("Bell","Conical","Convex","Flat","Knobbed","Sunken"))
  shrooms$`CapShape`[shrooms$`CapShape` == "b"] = "Bell"
  shrooms$`CapShape`[shrooms$`CapShape` == "c"] = "Conical"
  shrooms$`CapShape`[shrooms$`CapShape` == "x"] = "Convex"
  shrooms$`CapShape`[shrooms$`CapShape` == "f"] = "Flat"
  shrooms$`CapShape`[shrooms$`CapShape` == "k"] = "Knobbed"
  shrooms$`CapShape`[shrooms$`CapShape` == "s"] = "Sunken"
  
  #CapSurface
  levels(shrooms$`CapSurface`) = c(levels(shrooms$`CapSurface`), c("Fibrous", "Grooves", "Scaly", "Smooth"))
  shrooms$`CapSurface`[shrooms$`CapSurface` == "f"] = "Fibrous"
  shrooms$`CapSurface`[shrooms$`CapSurface` == "g"] = "Grooves"
  shrooms$`CapSurface`[shrooms$`CapSurface` == "y"] = "Scaly"
  shrooms$`CapSurface`[shrooms$`CapSurface` == "s"] = "Smooth"
  
  #CapColor
  levels(shrooms$`CapColor`) = c(levels(shrooms$`CapColor`), c("Brown", "Buff", "Cinnamon", "Gray", "Green", "Pink", "Purple", "Red", "White", "Yellow"))
  shrooms$`CapColor`[shrooms$`CapColor` == "n"] = "Brown"
  shrooms$`CapColor`[shrooms$`CapColor` == "b"] = "Buff"
  shrooms$`CapColor`[shrooms$`CapColor` == "c"] = "Cinnamon"
  shrooms$`CapColor`[shrooms$`CapColor` == "g"] = "Gray"
  shrooms$`CapColor`[shrooms$`CapColor` == "r"] = "Green"
  shrooms$`CapColor`[shrooms$`CapColor` == "p"] = "Pink"
  shrooms$`CapColor`[shrooms$`CapColor` == "u"] = "Purple"
  shrooms$`CapColor`[shrooms$`CapColor` == "e"] = "Red"
  shrooms$`CapColor`[shrooms$`CapColor` == "w"] = "White"
  shrooms$`CapColor`[shrooms$`CapColor` == "y"] = "Yellow"
  
  # Bruises
  levels(shrooms$Bruises) = c(levels(shrooms$Bruises), c("True","False"))
  shrooms$Bruises[shrooms$Bruises == "t"] = "True"
  shrooms$Bruises[shrooms$Bruises == "f"] = "False"
  
  #Odor
  levels(shrooms$Odor) = c(levels(shrooms$Odor), c("Almond", "Anise", "Creosote", "Fishy", "Foul", "Musty", "None", "Pungent", "Spicy"))
  shrooms$Odor[shrooms$Odor == "a"] = "Almond"
  shrooms$Odor[shrooms$Odor == "l"] = "Anise"
  shrooms$Odor[shrooms$Odor == "c"] = "Creosote"
  shrooms$Odor[shrooms$Odor == "y"] = "Fishy"
  shrooms$Odor[shrooms$Odor == "f"] = "Foul"
  shrooms$Odor[shrooms$Odor == "m"] = "Musty"
  shrooms$Odor[shrooms$Odor == "n"] = "None"
  shrooms$Odor[shrooms$Odor == "p"] = "Pungent"
  shrooms$Odor[shrooms$Odor == "s"] = "Spicy"
  
  # GillAttachment
  levels(shrooms$GillAttachment) = c(levels(shrooms$GillAttachment), c("Attached","Descending","Free","Notched"))
  shrooms$GillAttachment[shrooms$GillAttachment == "a"] = "Attached"
  shrooms$GillAttachment[shrooms$GillAttachment == "d"] = "Descending"
  shrooms$GillAttachment[shrooms$GillAttachment == "f"] = "Free"
  shrooms$GillAttachment[shrooms$GillAttachment == "n"] = "Notched"
  
  # GillSpacing
  levels(shrooms$GillSpacing) = c(levels(shrooms$GillSpacing), c("Close","Crowded","Distant"))
  shrooms$GillSpacing[shrooms$GillSpacing == "c"] = "Close"
  shrooms$GillSpacing[shrooms$GillSpacing == "w"] = "Crowded"
  shrooms$GillSpacing[shrooms$GillSpacing == "d"] = "Distant"
  
  # GillSize
  levels(shrooms$GillSize) = c(levels(shrooms$GillSize), c("Broad","Narrow"))
  shrooms$GillSize[shrooms$GillSize == "b"] = "Broad"
  shrooms$GillSize[shrooms$GillSize == "n"] = "Narrow"
  
  # GillColor
  levels(shrooms$GillColor) = c(levels(shrooms$GillColor), c("Black","Brown","Buff","Chocolate","Gray","Green","Orange","Pink","Purple","Red","White","Yellow"))
  shrooms$GillColor[shrooms$GillColor == "k"] = "Black"
  shrooms$GillColor[shrooms$GillColor == "n"] = "Brown"
  shrooms$GillColor[shrooms$GillColor == "b"] = "Buff"
  shrooms$GillColor[shrooms$GillColor == "h"] = "Chocolate"
  shrooms$GillColor[shrooms$GillColor == "g"] = "Gray"
  shrooms$GillColor[shrooms$GillColor == "r"] = "Green"
  shrooms$GillColor[shrooms$GillColor == "o"] = "Orange"
  shrooms$GillColor[shrooms$GillColor == "p"] = "Pink"
  shrooms$GillColor[shrooms$GillColor == "u"] = "Purple"
  shrooms$GillColor[shrooms$GillColor == "e"] = "Red"
  shrooms$GillColor[shrooms$GillColor == "w"] = "White"
  shrooms$GillColor[shrooms$GillColor == "y"] = "Yellow"
  
  # StalkShape
  levels(shrooms$StalkShape) = c(levels(shrooms$StalkShape), c("Enlarging","Tapering"))
  shrooms$StalkShape[shrooms$StalkShape == "e"] = "Enlarging"
  shrooms$StalkShape[shrooms$StalkShape == "t"] = "Tapering"
  
  # StalkRoot
  levels(shrooms$StalkRoot) = c(levels(shrooms$StalkRoot), c("Bulbous","Club","Cup","Equal","Rhizomorphs","Rooted","Missing"))
  shrooms$StalkRoot[shrooms$StalkRoot == "b"] = "Bulbous"
  shrooms$StalkRoot[shrooms$StalkRoot == "c"] = "Club"
  shrooms$StalkRoot[shrooms$StalkRoot == "u"] = "Cup"
  shrooms$StalkRoot[shrooms$StalkRoot == "e"] = "Equal"
  shrooms$StalkRoot[shrooms$StalkRoot == "z"] = "Rhizomorphs"
  shrooms$StalkRoot[shrooms$StalkRoot == "r"] = "Rooted"
  shrooms$StalkRoot[shrooms$StalkRoot == "?"] = "Missing"
  
  # StalkSurfaceAboveRing
  levels(shrooms$StalkSurfaceAboveRing) = c(levels(shrooms$StalkSurfaceAboveRing), c("Fibrous","Scaly","Silky","Smooth"))
  shrooms$StalkSurfaceAboveRing[shrooms$StalkSurfaceAboveRing == "f"] = "Fibrous"
  shrooms$StalkSurfaceAboveRing[shrooms$StalkSurfaceAboveRing == "y"] = "Scaly"
  shrooms$StalkSurfaceAboveRing[shrooms$StalkSurfaceAboveRing == "k"] = "Silky"
  shrooms$StalkSurfaceAboveRing[shrooms$StalkSurfaceAboveRing == "s"] = "Smooth"
  
  # StalkSurfaceBelowRing
  levels(shrooms$StalkSurfaceBelowRing) = c(levels(shrooms$StalkSurfaceBelowRing), c("Fibrous","Scaly","Silky","Smooth"))
  shrooms$StalkSurfaceBelowRing[shrooms$StalkSurfaceBelowRing == "f"] = "Fibrous"
  shrooms$StalkSurfaceBelowRing[shrooms$StalkSurfaceBelowRing == "y"] = "Scaly"
  shrooms$StalkSurfaceBelowRing[shrooms$StalkSurfaceBelowRing == "k"] = "Silky"
  shrooms$StalkSurfaceBelowRing[shrooms$StalkSurfaceBelowRing == "s"] = "Smooth"
  
  # StalkColorAboveRing
  levels(shrooms$StalkColorAboveRing) = c(levels(shrooms$StalkColorAboveRing), c("Brown","Buff","Cinnamon","Gray","Orange","Pink","Red","White","Yellow"))
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "n"] = "Brown"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "b"] = "Buff"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "c"] = "Cinnamon"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "g"] = "Gray"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "o"] = "Orange"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "p"] = "Pink"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "e"] = "Red"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "w"] = "White"
  shrooms$StalkColorAboveRing[shrooms$StalkColorAboveRing == "y"] = "Yellow"
  
  
  # StalkColorBelowRing
  levels(shrooms$StalkColorBelowRing) = c(levels(shrooms$StalkColorBelowRing), c("Brown","Buff","Cinnamon","Gray","Orange","Pink","Red","White","Yellow"))
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "n"] = "Brown"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "b"] = "Buff"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "c"] = "Cinnamon"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "g"] = "Gray"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "o"] = "Orange"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "p"] = "Pink"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "e"] = "Red"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "w"] = "White"
  shrooms$StalkColorBelowRing[shrooms$StalkColorBelowRing == "y"] = "Yellow"
  
  # VeilType
  levels(shrooms$VeilType) = c(levels(shrooms$VeilType), c("Partial","Universal"))
  shrooms$VeilType[shrooms$VeilType == "p"] = "Partial"
  shrooms$VeilType[shrooms$VeilType == "u"] = "Universal"
  
  # VeilColor
  levels(shrooms$VeilColor) = c(levels(shrooms$VeilColor), c("Brown","Orange","White","Yellow"))
  shrooms$VeilColor[shrooms$VeilColor == "n"] = "Brown"
  shrooms$VeilColor[shrooms$VeilColor == "o"] = "Orange"
  shrooms$VeilColor[shrooms$VeilColor == "w"] = "White"
  shrooms$VeilColor[shrooms$VeilColor == "y"] = "Yellow"
  
  # RingNumber
  levels(shrooms$RingNumber) = c(levels(shrooms$RingNumber), c("None","One","Two"))
  shrooms$RingNumber[shrooms$RingNumber == "n"] = "None"
  shrooms$RingNumber[shrooms$RingNumber == "o"] = "One"
  shrooms$RingNumber[shrooms$RingNumber == "t"] = "Two"
  
  # RingType
  levels(shrooms$RingType) = c(levels(shrooms$RingType), c("Cobwebby","Evanescent","Flaring","Large","None","Pendant","Sheathing","Zone"))
  shrooms$RingType[shrooms$RingType == "c"] = "Cobwebby"
  shrooms$RingType[shrooms$RingType == "e"] = "Evanescent"
  shrooms$RingType[shrooms$RingType == "f"] = "Flaring"
  shrooms$RingType[shrooms$RingType == "l"] = "Large"
  shrooms$RingType[shrooms$RingType == "n"] = "None"
  shrooms$RingType[shrooms$RingType == "p"] = "Pendant"
  shrooms$RingType[shrooms$RingType == "s"] = "Sheathing"
  shrooms$RingType[shrooms$RingType == "z"] = "Zone"
  
  # SporePrintColor
  levels(shrooms$SporePrintColor) = c(levels(shrooms$SporePrintColor), c("Black","Brown","Buff","Chocolate","Green","Orange","Purple","White","Yellow"))
  shrooms$SporePrintColor[shrooms$SporePrintColor == "k"] = "Black"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "n"] = "Brown"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "b"] = "Buff"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "h"] = "Chocolate"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "r"] = "Green"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "o"] = "Orange"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "u"] = "Purple"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "w"] = "White"
  shrooms$SporePrintColor[shrooms$SporePrintColor == "y"] = "Yellow"
  
  # Population
  levels(shrooms$Population) = c(levels(shrooms$Population), c("Abundnant","Clustered","Numerous","Scattered","Several","Solitary"))
  shrooms$Population[shrooms$Population == "a"] = "Abundnant"
  shrooms$Population[shrooms$Population == "c"] = "Clustered"
  shrooms$Population[shrooms$Population == "n"] = "Numerous"
  shrooms$Population[shrooms$Population == "s"] = "Scattered"
  shrooms$Population[shrooms$Population == "v"] = "Several"
  shrooms$Population[shrooms$Population == "y"] = "Solitary"
  
  # Habitat
  levels(shrooms$Habitat) = c(levels(shrooms$Habitat), c("Grasses","Leaves","Meadows","Paths","Urban","Waste","Woods"))
  shrooms$Habitat[shrooms$Habitat == "g"] = "Grasses"
  shrooms$Habitat[shrooms$Habitat == "l"] = "Leaves"
  shrooms$Habitat[shrooms$Habitat == "m"] = "Meadows"
  shrooms$Habitat[shrooms$Habitat == "p"] = "Paths"
  shrooms$Habitat[shrooms$Habitat == "u"] = "Urban"
  shrooms$Habitat[shrooms$Habitat == "w"] = "Waste"
  shrooms$Habitat[shrooms$Habitat == "d"] = "Woods"
  
  return(shrooms)
}
\end{lstlisting}



\clearpage

\label{figCluster}
\begin{figure}[H]
\caption {clustData function for clustering Mushroom dataset}
\end {figure}
    \begin{lstlisting}
    #Clustering Function
clustData <- function (df,ClassIndex,kmeansClasses = rep(0,unique(df[,ClassIndex]))) {
  # use split function to split the dataset according to the class label
  # a set of dataframes each representing a class label will be stored
  # in dfs list()
  dfs <- split (df, df[,ClassIndex])
  # create empty list
  clustList <- list()
  n <- length(dfs)
  for (i in 1:length(kmeansClasses)){
    # Cluster according to all features excluding the label
    if (kmeansClasses[i]>1 & kmeansClasses[i]< nrow(dfs[[i]])){
      clustList[[i]] <- kmeans(dfs[[i]][,-ClassIndex],kmeansClasses[i])
      #plotcluster(clustList[[i]], clustList[[i]]$cluster)
      dfs[[i]]$cluster <- paste0((dfs[[i]][,ClassIndex]),
                                 "_","c",clustList[[i]]$cluster)
    }
    else {
      dfs[[i]]$cluster = paste0((dfs[[i]][,ClassIndex]),
                                "_c0")
    }
  }
  # put all list elements in a dataframe and return it
  # note that ldply() require the library plyr
  allClusteredElements <- ldply (dfs, data.frame)
  # drop the first column 'id' resulting from ldply
  allClusteredElements <- allClusteredElements[,-1]
  allClusteredElements <- allClusteredElements[,-ClassIndex]
  return(allClusteredElements)
}
\end{lstlisting}



\end{document}
